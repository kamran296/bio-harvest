{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.059875,
     "end_time": "2020-12-15T06:52:44.191791",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.131916",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ☘️ PLANT DISEASE CLASSIFICATION USING RESNET-9 ☘️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corresponding Kaggle notebook can be accessed [here](https://www.kaggle.com/atharvaingle/plant-disease-classification-resnet-99-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.055768,
     "end_time": "2020-12-15T06:52:44.334852",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.279084",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### ⚠️⚠️⚠️DISCLAIMER: This notebook is beginner friendly, so don't worry if you don't know much about CNNs and Pytorch. Even if you have used TensorFlow in the past and are new to PyTorch, hang in there, everything is explained clearly and concisely. You will get a good overview of how to use PyTorch for image classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056728,
     "end_time": "2020-12-15T06:52:44.447613",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.390885",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Description of the dataset 📝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056692,
     "end_time": "2020-12-15T06:52:44.560771",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.504079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This dataset is created using offline augmentation from the original dataset. The original PlantVillage Dataset can be found [here](https://github.com/spMohanty/PlantVillage-Dataset).This dataset consists of about 87K rgb images of healthy and diseased crop leaves which is categorized into 38 different classes. The total dataset is divided into 80/20 ratio of training and validation set preserving the directory structure. A new directory containing 33 test images is created later for prediction purpose.\n",
    "\n",
    "Note: This description is given in the dataset itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.057571,
     "end_time": "2020-12-15T06:52:44.675922",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.618351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Our goal 🎯\n",
    "Goal is clear and simple. We need to build a model, which can classify between healthy and diseased crop leaves and also if the crop have any disease, predict which disease is it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056957,
     "end_time": "2020-12-15T06:52:44.789985",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.733028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Let's get started...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.056658,
     "end_time": "2020-12-15T06:52:44.903338",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.846680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.057862,
     "end_time": "2020-12-15T06:52:45.017851",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.959989",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:45.138567Z",
     "iopub.status.busy": "2020-12-15T06:52:45.137630Z",
     "iopub.status.idle": "2020-12-15T06:52:54.285881Z",
     "shell.execute_reply": "2020-12-15T06:52:54.284792Z"
    },
    "papermill": {
     "duration": 9.211344,
     "end_time": "2020-12-15T06:52:54.286015",
     "exception": false,
     "start_time": "2020-12-15T06:52:45.074671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.058411,
     "end_time": "2020-12-15T06:52:54.403660",
     "exception": false,
     "start_time": "2020-12-15T06:52:54.345249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We would require torchsummary library to print the model's summary in keras style (nicely formatted and pretty to look) as Pytorch natively doesn't support that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:54.531023Z",
     "iopub.status.busy": "2020-12-15T06:52:54.530191Z",
     "iopub.status.idle": "2020-12-15T06:52:56.166219Z",
     "shell.execute_reply": "2020-12-15T06:52:56.164951Z"
    },
    "papermill": {
     "duration": 1.704433,
     "end_time": "2020-12-15T06:52:56.166377",
     "exception": false,
     "start_time": "2020-12-15T06:52:54.461944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os                       # for working with files\n",
    "import numpy as np              # for numerical computationss\n",
    "import pandas as pd             # for working with dataframes\n",
    "import torch                    # Pytorch module \n",
    "import matplotlib.pyplot as plt # for plotting informations on graph and images using tensors\n",
    "import torch.nn as nn           # for creating  neural networks\n",
    "from torch.utils.data import DataLoader # for dataloaders \n",
    "from PIL import Image           # for checking images\n",
    "import torch.nn.functional as F # for functions for calculating loss\n",
    "import torchvision.transforms as transforms   # for transforming images into tensors \n",
    "from torchvision.utils import make_grid       # for data checking\n",
    "from torchvision.datasets import ImageFolder  # for working with classes and images\n",
    "from torchsummary import summary              # for getting the summary of our model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.058296,
     "end_time": "2020-12-15T06:52:56.283998",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.225702",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🧭 Exploring the data 🧭"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.05825,
     "end_time": "2020-12-15T06:52:56.400725",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.342475",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:56.522416Z",
     "iopub.status.busy": "2020-12-15T06:52:56.521802Z",
     "iopub.status.idle": "2020-12-15T06:52:56.536807Z",
     "shell.execute_reply": "2020-12-15T06:52:56.536213Z"
    },
    "papermill": {
     "duration": 0.07813,
     "end_time": "2020-12-15T06:52:56.536899",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.458769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m valid_dir \u001b[38;5;241m=\u001b[39m data_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/valid\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_dir)\n\u001b[1;32m----> 5\u001b[0m diseases \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'"
     ]
    }
   ],
   "source": [
    "data_dir = \"../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)\"\n",
    "train_dir = data_dir + \"/train\"\n",
    "valid_dir = data_dir + \"/valid\"\n",
    "print(train_dir)\n",
    "diseases = os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:56.660806Z",
     "iopub.status.busy": "2020-12-15T06:52:56.660131Z",
     "iopub.status.idle": "2020-12-15T06:52:56.663554Z",
     "shell.execute_reply": "2020-12-15T06:52:56.664320Z"
    },
    "papermill": {
     "duration": 0.068176,
     "end_time": "2020-12-15T06:52:56.664465",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.596289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'diseases' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# printing the disease names\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdiseases\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'diseases' is not defined"
     ]
    }
   ],
   "source": [
    "# printing the disease names\n",
    "print(diseases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:56.789812Z",
     "iopub.status.busy": "2020-12-15T06:52:56.789079Z",
     "iopub.status.idle": "2020-12-15T06:52:56.792917Z",
     "shell.execute_reply": "2020-12-15T06:52:56.792464Z"
    },
    "papermill": {
     "duration": 0.068791,
     "end_time": "2020-12-15T06:52:56.793019",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.724228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'diseases' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal disease classes are: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(\u001b[43mdiseases\u001b[49m)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'diseases' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Total disease classes are: {}\".format(len(diseases)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:56.922040Z",
     "iopub.status.busy": "2020-12-15T06:52:56.921156Z",
     "iopub.status.idle": "2020-12-15T06:52:56.924421Z",
     "shell.execute_reply": "2020-12-15T06:52:56.923843Z"
    },
    "papermill": {
     "duration": 0.071422,
     "end_time": "2020-12-15T06:52:56.924536",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.853114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'diseases' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m plants \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m NumberOfDiseases \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m plant \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdiseases\u001b[49m:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m plant\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m___\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m plants:\n\u001b[0;32m      5\u001b[0m         plants\u001b[38;5;241m.\u001b[39mappend(plant\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m___\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'diseases' is not defined"
     ]
    }
   ],
   "source": [
    "plants = []\n",
    "NumberOfDiseases = 0\n",
    "for plant in diseases:\n",
    "    if plant.split('___')[0] not in plants:\n",
    "        plants.append(plant.split('___')[0])\n",
    "    if plant.split('___')[1] != 'healthy':\n",
    "        NumberOfDiseases += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.069462,
     "end_time": "2020-12-15T06:52:57.055273",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.985811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The above cell extract the number of unique plants and number of unique diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:57.183047Z",
     "iopub.status.busy": "2020-12-15T06:52:57.182397Z",
     "iopub.status.idle": "2020-12-15T06:52:57.186314Z",
     "shell.execute_reply": "2020-12-15T06:52:57.185696Z"
    },
    "papermill": {
     "duration": 0.068933,
     "end_time": "2020-12-15T06:52:57.186415",
     "exception": false,
     "start_time": "2020-12-15T06:52:57.117482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Plants are: \n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# unique plants in the dataset\n",
    "print(f\"Unique Plants are: \\n{plants}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:57.313744Z",
     "iopub.status.busy": "2020-12-15T06:52:57.313076Z",
     "iopub.status.idle": "2020-12-15T06:52:57.316355Z",
     "shell.execute_reply": "2020-12-15T06:52:57.317088Z"
    },
    "papermill": {
     "duration": 0.069891,
     "end_time": "2020-12-15T06:52:57.317251",
     "exception": false,
     "start_time": "2020-12-15T06:52:57.247360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of plants: 0\n"
     ]
    }
   ],
   "source": [
    "# number of unique plants\n",
    "print(\"Number of plants: {}\".format(len(plants)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:57.444856Z",
     "iopub.status.busy": "2020-12-15T06:52:57.444130Z",
     "iopub.status.idle": "2020-12-15T06:52:57.447598Z",
     "shell.execute_reply": "2020-12-15T06:52:57.448386Z"
    },
    "papermill": {
     "duration": 0.069339,
     "end_time": "2020-12-15T06:52:57.448580",
     "exception": false,
     "start_time": "2020-12-15T06:52:57.379241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of diseases: 0\n"
     ]
    }
   ],
   "source": [
    "# number of unique diseases\n",
    "print(\"Number of diseases: {}\".format(NumberOfDiseases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.062489,
     "end_time": "2020-12-15T06:52:57.574134",
     "exception": false,
     "start_time": "2020-12-15T06:52:57.511645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So we have images of leaves of 14 plants and while excluding healthy leaves, we have 26 types of images that show a particular disease in a particular plant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:57.704194Z",
     "iopub.status.busy": "2020-12-15T06:52:57.703583Z",
     "iopub.status.idle": "2020-12-15T06:53:03.960106Z",
     "shell.execute_reply": "2020-12-15T06:53:03.960800Z"
    },
    "papermill": {
     "duration": 6.323955,
     "end_time": "2020-12-15T06:53:03.960987",
     "exception": false,
     "start_time": "2020-12-15T06:52:57.637032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'diseases' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Number of images for each disease\u001b[39;00m\n\u001b[0;32m      2\u001b[0m nums \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m disease \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdiseases\u001b[49m:\n\u001b[0;32m      4\u001b[0m     nums[disease] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(train_dir \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m disease))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# converting the nums dictionary to pandas dataframe passing index as plant name and number of images as column\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'diseases' is not defined"
     ]
    }
   ],
   "source": [
    "# Number of images for each disease\n",
    "nums = {}\n",
    "for disease in diseases:\n",
    "    nums[disease] = len(os.listdir(train_dir + '/' + disease))\n",
    "    \n",
    "# converting the nums dictionary to pandas dataframe passing index as plant name and number of images as column\n",
    "\n",
    "img_per_class = pd.DataFrame(nums.values(), index=nums.keys(), columns=[\"no. of images\"])\n",
    "img_per_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.090681,
     "end_time": "2020-12-15T06:53:04.148485",
     "exception": false,
     "start_time": "2020-12-15T06:53:04.057804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Visualizing the above information on a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:53:04.334832Z",
     "iopub.status.busy": "2020-12-15T06:53:04.333992Z",
     "iopub.status.idle": "2020-12-15T06:53:04.860737Z",
     "shell.execute_reply": "2020-12-15T06:53:04.859673Z"
    },
    "papermill": {
     "duration": 0.623297,
     "end_time": "2020-12-15T06:53:04.860887",
     "exception": false,
     "start_time": "2020-12-15T06:53:04.237590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (38,) and arg 1 with shape (0,).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m index \u001b[38;5;241m=\u001b[39m [n \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m38\u001b[39m)]\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m----> 4\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnums\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlants/Diseases\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo of images available\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\pyplot.py:2439\u001b[0m, in \u001b[0;36mbar\u001b[1;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[0;32m   2435\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mbar)\n\u001b[0;32m   2436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbar\u001b[39m(\n\u001b[0;32m   2437\u001b[0m         x, height, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, bottom\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, align\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   2438\u001b[0m         data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2440\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbottom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbottom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2441\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\__init__.py:1459\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1459\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1461\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1462\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1463\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:2417\u001b[0m, in \u001b[0;36mAxes.bar\u001b[1;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[0;32m   2414\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m yerr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2415\u001b[0m         yerr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_dx(yerr, y0, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_yunits)\n\u001b[1;32m-> 2417\u001b[0m x, height, width, y, linewidth, hatch \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2418\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Make args iterable too.\u001b[39;49;00m\n\u001b[0;32m   2419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matleast_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2421\u001b[0m \u001b[38;5;66;03m# Now that units have been converted, set the tick locations.\u001b[39;00m\n\u001b[0;32m   2422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orientation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mbroadcast_arrays\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\stride_tricks.py:540\u001b[0m, in \u001b[0;36mbroadcast_arrays\u001b[1;34m(subok, *args)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;66;03m# nditer is not used here to avoid the limit of 32 arrays.\u001b[39;00m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;66;03m# Otherwise, something like the following one-liner would suffice:\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;66;03m# return np.nditer(args, flags=['multi_index', 'zerosize_ok'],\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;66;03m#                  order='C').itviews\u001b[39;00m\n\u001b[0;32m    538\u001b[0m args \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39marray(_m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, subok\u001b[38;5;241m=\u001b[39msubok) \u001b[38;5;28;01mfor\u001b[39;00m _m \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m--> 540\u001b[0m shape \u001b[38;5;241m=\u001b[39m \u001b[43m_broadcast_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(array\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m shape \u001b[38;5;28;01mfor\u001b[39;00m array \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;66;03m# Common case where nothing needs to be broadcasted.\u001b[39;00m\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\stride_tricks.py:422\u001b[0m, in \u001b[0;36m_broadcast_shape\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the shape of the arrays that would result from broadcasting the\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;124;03msupplied arrays against each other.\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;66;03m# consistently\u001b[39;00m\n\u001b[1;32m--> 422\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;66;03m# unfortunately, it cannot handle 32 or more arguments directly\u001b[39;00m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;28mlen\u001b[39m(args), \u001b[38;5;241m31\u001b[39m):\n\u001b[0;32m    425\u001b[0m     \u001b[38;5;66;03m# ironically, np.broadcast does not properly handle np.broadcast\u001b[39;00m\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;66;03m# objects (it treats them as scalars)\u001b[39;00m\n\u001b[0;32m    427\u001b[0m     \u001b[38;5;66;03m# use broadcasting to avoid allocating the full array\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (38,) and arg 1 with shape (0,)."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting number of images available for each disease\n",
    "index = [n for n in range(38)]\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.bar(index, [n for n in nums.values()], width=0.3)\n",
    "plt.xlabel('Plants/Diseases', fontsize=10)\n",
    "plt.ylabel('No of images available', fontsize=10)\n",
    "plt.xticks(index, diseases, fontsize=5, rotation=90)\n",
    "plt.title('Images per each class of plant disease')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.068183,
     "end_time": "2020-12-15T06:53:04.997832",
     "exception": false,
     "start_time": "2020-12-15T06:53:04.929649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can see that the dataset is almost balanced for all classes, so we are good to go forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.073886,
     "end_time": "2020-12-15T06:53:05.152902",
     "exception": false,
     "start_time": "2020-12-15T06:53:05.079016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Images available for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:53:05.285106Z",
     "iopub.status.busy": "2020-12-15T06:53:05.284437Z",
     "iopub.status.idle": "2020-12-15T06:53:05.287876Z",
     "shell.execute_reply": "2020-12-15T06:53:05.288406Z"
    },
    "papermill": {
     "duration": 0.07225,
     "end_time": "2020-12-15T06:53:05.288530",
     "exception": false,
     "start_time": "2020-12-15T06:53:05.216280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 images for training\n"
     ]
    }
   ],
   "source": [
    "n_train = 0\n",
    "for value in nums.values():\n",
    "    n_train += value\n",
    "print(f\"There are {n_train} images for training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.064118,
     "end_time": "2020-12-15T06:53:05.416780",
     "exception": false,
     "start_time": "2020-12-15T06:53:05.352662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🍳 Data Preparation for training 🍳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:53:05.548188Z",
     "iopub.status.busy": "2020-12-15T06:53:05.547365Z",
     "iopub.status.idle": "2020-12-15T06:54:23.286526Z",
     "shell.execute_reply": "2020-12-15T06:54:23.285629Z"
    },
    "papermill": {
     "duration": 77.805914,
     "end_time": "2020-12-15T06:54:23.286647",
     "exception": false,
     "start_time": "2020-12-15T06:53:05.480733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# datasets for validation and training\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mToTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m valid \u001b[38;5;241m=\u001b[39m ImageFolder(valid_dir, transform\u001b[38;5;241m=\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mToTensor()) \n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py:309\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    303\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    307\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    308\u001b[0m ):\n\u001b[1;32m--> 309\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py:144\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    136\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    142\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[1;32m--> 144\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py:218\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m    192\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py:40\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train'"
     ]
    }
   ],
   "source": [
    "# datasets for validation and training\n",
    "train = ImageFolder(train_dir, transform=transforms.ToTensor())\n",
    "valid = ImageFolder(valid_dir, transform=transforms.ToTensor()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.063883,
     "end_time": "2020-12-15T06:54:23.415740",
     "exception": false,
     "start_time": "2020-12-15T06:54:23.351857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`torchvision.datasets` is a class which helps in loading all common and famous datasets. It also helps in loading custom datasets. I have used subclass `torchvision.datasets.ImageFolder` which helps in loading the image data when the data is arranged in this way:\n",
    "\n",
    "----------------\n",
    "root/dog/xxx.png\n",
    "\n",
    "root/dog/xxy.png\n",
    "\n",
    "root/dog/xxz.png\n",
    "\n",
    "<br>\n",
    "\n",
    "root/cat/123.png\n",
    "\n",
    "root/cat/nsdf3.png\n",
    "\n",
    "root/cat/asd932_.png\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.06452,
     "end_time": "2020-12-15T06:54:23.544775",
     "exception": false,
     "start_time": "2020-12-15T06:54:23.480255",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, after loading the data, we need to transform the pixel values of each image (0-255) to 0-1 as neural networks works quite good with normalized data. The entire array of pixel values is converted to torch [tensor](https://pytorch.org/tutorials/beginner/examples_tensor/two_layer_net_tensor.html#:~:text=A%20PyTorch%20Tensor%20is%20basically,used%20for%20arbitrary%20numeric%20computation.) and then divided by 255.\n",
    "If you are not familiar why normalizing inputs help neural network, read [this](https://towardsdatascience.com/why-data-should-be-normalized-before-training-a-neural-network-c626b7f66c7d) post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.064216,
     "end_time": "2020-12-15T06:54:23.673604",
     "exception": false,
     "start_time": "2020-12-15T06:54:23.609388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Image shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:23.808409Z",
     "iopub.status.busy": "2020-12-15T06:54:23.807761Z",
     "iopub.status.idle": "2020-12-15T06:54:23.882316Z",
     "shell.execute_reply": "2020-12-15T06:54:23.881570Z"
    },
    "papermill": {
     "duration": 0.144539,
     "end_time": "2020-12-15T06:54:23.882452",
     "exception": false,
     "start_time": "2020-12-15T06:54:23.737913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img, label \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(img\u001b[38;5;241m.\u001b[39mshape, label)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "img, label = train[0]\n",
    "print(img.shape, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.065861,
     "end_time": "2020-12-15T06:54:24.014531",
     "exception": false,
     "start_time": "2020-12-15T06:54:23.948670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can see the shape (3, 256 256) of the image. 3 is the number of channels (RGB) and 256 x 256 is the width and height of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:24.153767Z",
     "iopub.status.busy": "2020-12-15T06:54:24.153071Z",
     "iopub.status.idle": "2020-12-15T06:54:24.158913Z",
     "shell.execute_reply": "2020-12-15T06:54:24.159444Z"
    },
    "papermill": {
     "duration": 0.075821,
     "end_time": "2020-12-15T06:54:24.159608",
     "exception": false,
     "start_time": "2020-12-15T06:54:24.083787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# total number of classes in train set\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain\u001b[49m\u001b[38;5;241m.\u001b[39mclasses)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "# total number of classes in train set\n",
    "len(train.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:24.296508Z",
     "iopub.status.busy": "2020-12-15T06:54:24.295743Z",
     "iopub.status.idle": "2020-12-15T06:54:24.298712Z",
     "shell.execute_reply": "2020-12-15T06:54:24.298233Z"
    },
    "papermill": {
     "duration": 0.073411,
     "end_time": "2020-12-15T06:54:24.298812",
     "exception": false,
     "start_time": "2020-12-15T06:54:24.225401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for checking some images from training dataset\n",
    "def show_image(image, label):\n",
    "    print(\"Label :\" + train.classes[label] + \"(\" + str(label) + \")\")\n",
    "    plt.imshow(image.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.065343,
     "end_time": "2020-12-15T06:54:24.429052",
     "exception": false,
     "start_time": "2020-12-15T06:54:24.363709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 🖼️ Some Images from training dataset 🖼️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:24.563829Z",
     "iopub.status.busy": "2020-12-15T06:54:24.562998Z",
     "iopub.status.idle": "2020-12-15T06:54:24.742565Z",
     "shell.execute_reply": "2020-12-15T06:54:24.743009Z"
    },
    "papermill": {
     "duration": 0.249149,
     "end_time": "2020-12-15T06:54:24.743136",
     "exception": false,
     "start_time": "2020-12-15T06:54:24.493987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m show_image(\u001b[38;5;241m*\u001b[39m\u001b[43mtrain\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "show_image(*train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:24.886131Z",
     "iopub.status.busy": "2020-12-15T06:54:24.885530Z",
     "iopub.status.idle": "2020-12-15T06:54:25.070966Z",
     "shell.execute_reply": "2020-12-15T06:54:25.071491Z"
    },
    "papermill": {
     "duration": 0.257666,
     "end_time": "2020-12-15T06:54:25.071640",
     "exception": false,
     "start_time": "2020-12-15T06:54:24.813974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m show_image(\u001b[38;5;241m*\u001b[39m\u001b[43mtrain\u001b[49m[\u001b[38;5;241m70000\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "show_image(*train[70000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:25.232428Z",
     "iopub.status.busy": "2020-12-15T06:54:25.231738Z",
     "iopub.status.idle": "2020-12-15T06:54:25.478718Z",
     "shell.execute_reply": "2020-12-15T06:54:25.479256Z"
    },
    "papermill": {
     "duration": 0.328314,
     "end_time": "2020-12-15T06:54:25.479394",
     "exception": false,
     "start_time": "2020-12-15T06:54:25.151080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m show_image(\u001b[38;5;241m*\u001b[39m\u001b[43mtrain\u001b[49m[\u001b[38;5;241m30000\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "show_image(*train[30000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:25.648270Z",
     "iopub.status.busy": "2020-12-15T06:54:25.647636Z",
     "iopub.status.idle": "2020-12-15T06:54:25.655836Z",
     "shell.execute_reply": "2020-12-15T06:54:25.655136Z"
    },
    "papermill": {
     "duration": 0.093711,
     "end_time": "2020-12-15T06:54:25.655943",
     "exception": false,
     "start_time": "2020-12-15T06:54:25.562232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1bb5349abf0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the seed value\n",
    "random_seed = 7\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:25.813296Z",
     "iopub.status.busy": "2020-12-15T06:54:25.812568Z",
     "iopub.status.idle": "2020-12-15T06:54:25.815698Z",
     "shell.execute_reply": "2020-12-15T06:54:25.815224Z"
    },
    "papermill": {
     "duration": 0.083405,
     "end_time": "2020-12-15T06:54:25.815796",
     "exception": false,
     "start_time": "2020-12-15T06:54:25.732391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setting the batch size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.076838,
     "end_time": "2020-12-15T06:54:25.968978",
     "exception": false,
     "start_time": "2020-12-15T06:54:25.892140",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`batch_size` is the total number of images given as input at once in forward propagation of the CNN. Basically, batch size defines the number of samples that will be propagated through the network.\n",
    "\n",
    "For instance, let's say you have 1050 training samples and you want to set up a batch_size equal to 100. The algorithm takes the first 100 samples (from 1st to 100th) from the training dataset and trains the network. Next, it takes the second 100 samples (from 101st to 200th) and trains the network again. We can keep doing this procedure until we have propagated all samples through of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:26.144973Z",
     "iopub.status.busy": "2020-12-15T06:54:26.143969Z",
     "iopub.status.idle": "2020-12-15T06:54:26.146484Z",
     "shell.execute_reply": "2020-12-15T06:54:26.147104Z"
    },
    "papermill": {
     "duration": 0.097126,
     "end_time": "2020-12-15T06:54:26.147260",
     "exception": false,
     "start_time": "2020-12-15T06:54:26.050134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# DataLoaders for training and validation\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_dl \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[43mtrain\u001b[49m, batch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m valid_dl \u001b[38;5;241m=\u001b[39m DataLoader(valid, batch_size, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "# DataLoaders for training and validation\n",
    "train_dl = DataLoader(train, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "valid_dl = DataLoader(valid, batch_size, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.07517,
     "end_time": "2020-12-15T06:54:26.300702",
     "exception": false,
     "start_time": "2020-12-15T06:54:26.225532",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- `DataLoader` is a subclass which comes from `torch.utils.data`. It helps in loading large and memory consuming datasets. It takes in `batch_size` which denotes the number of samples contained in each generated batch. \n",
    "\n",
    "- Setting `shuffle=True` shuffles the dataset. It is heplful so that batches between epochs do not look alike. Doing so will eventually make our model more robust.\n",
    "\n",
    "- `num_workers`, denotes the number of processes that generate batches in parallel. If you have more cores in your CPU, you can set it to number of cores in your CPU. Since, Kaggle provides a 2 core CPU, I have set it to 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:26.459616Z",
     "iopub.status.busy": "2020-12-15T06:54:26.458860Z",
     "iopub.status.idle": "2020-12-15T06:54:26.461331Z",
     "shell.execute_reply": "2020-12-15T06:54:26.461924Z"
    },
    "papermill": {
     "duration": 0.08434,
     "end_time": "2020-12-15T06:54:26.462045",
     "exception": false,
     "start_time": "2020-12-15T06:54:26.377705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# helper function to show a batch of training instances\n",
    "def show_batch(data):\n",
    "    for images, labels in data:\n",
    "        fig, ax = plt.subplots(figsize=(30, 30))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images, nrow=8).permute(1, 2, 0))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:26.996833Z",
     "iopub.status.busy": "2020-12-15T06:54:26.995790Z",
     "iopub.status.idle": "2020-12-15T06:54:33.581290Z",
     "shell.execute_reply": "2020-12-15T06:54:33.581925Z"
    },
    "papermill": {
     "duration": 7.0439,
     "end_time": "2020-12-15T06:54:33.582079",
     "exception": false,
     "start_time": "2020-12-15T06:54:26.538179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Images for first batch of training\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m show_batch(\u001b[43mtrain_dl\u001b[49m) \n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dl' is not defined"
     ]
    }
   ],
   "source": [
    "# Images for first batch of training\n",
    "show_batch(train_dl) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.148317,
     "end_time": "2020-12-15T06:54:33.881587",
     "exception": false,
     "start_time": "2020-12-15T06:54:33.733270",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🏗️ Modelling 🏗️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.149596,
     "end_time": "2020-12-15T06:54:34.178417",
     "exception": false,
     "start_time": "2020-12-15T06:54:34.028821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "It is advisable to use GPU instead of CPU when dealing with images dataset because CPUs are generalized for general purpose and GPUs are optimized for training deep learning models as they can process multiple computations simultaneously. They have a large number of cores, which allows for better computation of multiple parallel processes. Additionally, computations in deep learning need to handle huge amounts of data — this makes a GPU’s memory bandwidth most suitable.\n",
    "To seamlessly use a GPU, if one is available, we define a couple of helper functions (`get_default_device` & `to_device`) and a helper class `DeviceDataLoader` to move our model & data to the GPU as required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.145958,
     "end_time": "2020-12-15T06:54:34.470984",
     "exception": false,
     "start_time": "2020-12-15T06:54:34.325026",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:34.778895Z",
     "iopub.status.busy": "2020-12-15T06:54:34.777939Z",
     "iopub.status.idle": "2020-12-15T06:54:34.780617Z",
     "shell.execute_reply": "2020-12-15T06:54:34.781074Z"
    },
    "papermill": {
     "duration": 0.163682,
     "end_time": "2020-12-15T06:54:34.781228",
     "exception": false,
     "start_time": "2020-12-15T06:54:34.617546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for moving data into GPU (if available)\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available:\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "# for moving data to device (CPU or GPU)\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "# for loading in the device (GPU if available else CPU)\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.150399,
     "end_time": "2020-12-15T06:54:35.079034",
     "exception": false,
     "start_time": "2020-12-15T06:54:34.928635",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Checking the device we are working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:35.382785Z",
     "iopub.status.busy": "2020-12-15T06:54:35.381977Z",
     "iopub.status.idle": "2020-12-15T06:54:35.385943Z",
     "shell.execute_reply": "2020-12-15T06:54:35.385339Z"
    },
    "papermill": {
     "duration": 0.159177,
     "end_time": "2020-12-15T06:54:35.386046",
     "exception": false,
     "start_time": "2020-12-15T06:54:35.226869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.144885,
     "end_time": "2020-12-15T06:54:35.678263",
     "exception": false,
     "start_time": "2020-12-15T06:54:35.533378",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Wrap up our training and validation data loaders using `DeviceDataLoader` for automatically transferring batches of data to the GPU (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:35.989565Z",
     "iopub.status.busy": "2020-12-15T06:54:35.988272Z",
     "iopub.status.idle": "2020-12-15T06:54:35.991640Z",
     "shell.execute_reply": "2020-12-15T06:54:35.991102Z"
    },
    "papermill": {
     "duration": 0.163641,
     "end_time": "2020-12-15T06:54:35.991753",
     "exception": false,
     "start_time": "2020-12-15T06:54:35.828112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Moving data into GPU\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_dl \u001b[38;5;241m=\u001b[39m DeviceDataLoader(\u001b[43mtrain_dl\u001b[49m, device)\n\u001b[0;32m      3\u001b[0m valid_dl \u001b[38;5;241m=\u001b[39m DeviceDataLoader(valid_dl, device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dl' is not defined"
     ]
    }
   ],
   "source": [
    "# Moving data into GPU\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "valid_dl = DeviceDataLoader(valid_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.147431,
     "end_time": "2020-12-15T06:54:36.291718",
     "exception": false,
     "start_time": "2020-12-15T06:54:36.144287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 👷 Building the model architecture 👷"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.161795,
     "end_time": "2020-12-15T06:54:36.602798",
     "exception": false,
     "start_time": "2020-12-15T06:54:36.441003",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*We are going to use **ResNet**, which have been one of the major breakthrough in computer vision since they were introduced in 2015.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.151775,
     "end_time": "2020-12-15T06:54:36.903352",
     "exception": false,
     "start_time": "2020-12-15T06:54:36.751577",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If you want to learn more about ResNets read the following articles:\n",
    "- [Understanding and Visualizing ResNets](https://towardsdatascience.com/understanding-and-visualizing-resnets-442284831be8#:~:text=ResNet%20Layers,layers%20remains%20the%20same%20%E2%80%94%204.)\n",
    "- [Overview of ResNet and its variants](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035)\n",
    "- [Paper with code implementation](https://paperswithcode.com/method/resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.155226,
     "end_time": "2020-12-15T06:54:37.237565",
     "exception": false,
     "start_time": "2020-12-15T06:54:37.082339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In ResNets, unlike in traditional neural networks, each layer feeds into the next layer, we use a network with residual blocks, each layer feeds into the next layer and directly into the layers about 2–3 hops away, to avoid over-fitting (a situation when validation loss stop decreasing at a point and then keeps increasing while training loss still decreases). This also helps in preventing [vanishing gradient problem](https://towardsdatascience.com/the-vanishing-gradient-problem-69bf08b15484) and allow us to train deep neural networks. Here is a simple residual block:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.147927,
     "end_time": "2020-12-15T06:54:37.531608",
     "exception": false,
     "start_time": "2020-12-15T06:54:37.383681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![image](https://www.mdpi.com/remotesensing/remotesensing-11-01896/article_deploy/html/images/remotesensing-11-01896-g001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.147768,
     "end_time": "2020-12-15T06:54:37.826313",
     "exception": false,
     "start_time": "2020-12-15T06:54:37.678545",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Residual Block code implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:38.140386Z",
     "iopub.status.busy": "2020-12-15T06:54:38.139498Z",
     "iopub.status.idle": "2020-12-15T06:54:38.142557Z",
     "shell.execute_reply": "2020-12-15T06:54:38.142037Z"
    },
    "papermill": {
     "duration": 0.167702,
     "end_time": "2020-12-15T06:54:38.142655",
     "exception": false,
     "start_time": "2020-12-15T06:54:37.974953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleResidualBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.conv2(out)\n",
    "        return self.relu2(out) + x # ReLU can be applied before or after adding the input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.236061,
     "end_time": "2020-12-15T06:54:38.593529",
     "exception": false,
     "start_time": "2020-12-15T06:54:38.357468",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Then we define our `ImageClassificationBase` class whose functions are:**\n",
    "\n",
    "- `training_step` - To figure out how “wrong” the model is going after training or validation step.We are using this function other than just an accuracy metric that is likely not going to be differentiable (this would mean that the gradient can’t be determined, which is necessary for the model to improve during training)\n",
    "\n",
    "A quick look at the PyTorch docs that yields the cost function: [cross_entropy](https://pytorch.org/docs/stable/nn.functional.html#cross-entropy).\n",
    "\n",
    "- `validation_step` - Because an accuracy metric can’t be used while training the model, doesn’t mean it shouldn’t be implemented! Accuracy in this case would be measured by a threshold, and counted if the difference between the model’s prediction and the actual label is lower than that threshold.\n",
    "- `validation_epoch_end` - We want to track the validation losses/accuracies and train losses after each epoch, and every time we do so we have to make sure the gradient is not being tracked.\n",
    "- `epoch_end` - We also want to print validation losses/accuracies, train losses and learning rate too because we are using learning rate scheduler (which will change the learning rate after every batch of training) after each epoch.\n",
    "\n",
    "We also define an `accuracy` function which calculates the overall accuracy of the model on an entire batch of outputs, so that we can use it as a metric in `fit_one_cycle`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:39.367899Z",
     "iopub.status.busy": "2020-12-15T06:54:39.362848Z",
     "iopub.status.idle": "2020-12-15T06:54:39.389963Z",
     "shell.execute_reply": "2020-12-15T06:54:39.391114Z"
    },
    "papermill": {
     "duration": 0.532121,
     "end_time": "2020-12-15T06:54:39.391404",
     "exception": false,
     "start_time": "2020-12-15T06:54:38.859283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for calculating the accuracy\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "\n",
    "# base class for the model\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)                   # Generate prediction\n",
    "        loss = F.cross_entropy(out, labels)  # Calculate loss\n",
    "        acc = accuracy(out, labels)          # Calculate accuracy\n",
    "        return {\"val_loss\": loss.detach(), \"val_accuracy\": acc}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x[\"val_loss\"] for x in outputs]\n",
    "        batch_accuracy = [x[\"val_accuracy\"] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()       # Combine loss  \n",
    "        epoch_accuracy = torch.stack(batch_accuracy).mean()\n",
    "        return {\"val_loss\": epoch_loss, \"val_accuracy\": epoch_accuracy} # Combine accuracies\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_accuracy']))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.203515,
     "end_time": "2020-12-15T06:54:39.894829",
     "exception": false,
     "start_time": "2020-12-15T06:54:39.691314",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 👷 Defining the final architecture of our model 👷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:40.222910Z",
     "iopub.status.busy": "2020-12-15T06:54:40.222083Z",
     "iopub.status.idle": "2020-12-15T06:54:40.226361Z",
     "shell.execute_reply": "2020-12-15T06:54:40.225720Z"
    },
    "papermill": {
     "duration": 0.17469,
     "end_time": "2020-12-15T06:54:40.226460",
     "exception": false,
     "start_time": "2020-12-15T06:54:40.051770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Architecture for training\n",
    "\n",
    "# convolution block with BatchNormalization\n",
    "def ConvBlock(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "             nn.BatchNorm2d(out_channels),\n",
    "             nn.ReLU(inplace=True)]\n",
    "    if pool:\n",
    "        layers.append(nn.MaxPool2d(4))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# resnet architecture \n",
    "class ResNet9(ImageClassificationBase):\n",
    "    def __init__(self, in_channels, num_diseases):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = ConvBlock(in_channels, 64)\n",
    "        self.conv2 = ConvBlock(64, 128, pool=True) # out_dim : 128 x 64 x 64 \n",
    "        self.res1 = nn.Sequential(ConvBlock(128, 128), ConvBlock(128, 128))\n",
    "        \n",
    "        self.conv3 = ConvBlock(128, 256, pool=True) # out_dim : 256 x 16 x 16\n",
    "        self.conv4 = ConvBlock(256, 512, pool=True) # out_dim : 512 x 4 x 44\n",
    "        self.res2 = nn.Sequential(ConvBlock(512, 512), ConvBlock(512, 512))\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n",
    "                                       nn.Flatten(),\n",
    "                                       nn.Linear(512, num_diseases))\n",
    "        \n",
    "    def forward(self, xb): # xb is the loaded batch\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.classifier(out)\n",
    "        return out        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.149615,
     "end_time": "2020-12-15T06:54:40.527855",
     "exception": false,
     "start_time": "2020-12-15T06:54:40.378240",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we define a model object and transfer it into the device with which we are working..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:40.847626Z",
     "iopub.status.busy": "2020-12-15T06:54:40.846635Z",
     "iopub.status.idle": "2020-12-15T06:54:40.918385Z",
     "shell.execute_reply": "2020-12-15T06:54:40.918921Z"
    },
    "papermill": {
     "duration": 0.237477,
     "end_time": "2020-12-15T06:54:40.919048",
     "exception": false,
     "start_time": "2020-12-15T06:54:40.681571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# defining the model and moving it to the GPU\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m to_device(ResNet9(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain\u001b[49m\u001b[38;5;241m.\u001b[39mclasses)), device) \n\u001b[0;32m      3\u001b[0m model\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "# defining the model and moving it to the GPU\n",
    "model = to_device(ResNet9(3, len(train.classes)), device) \n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.150064,
     "end_time": "2020-12-15T06:54:41.225021",
     "exception": false,
     "start_time": "2020-12-15T06:54:41.074957",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*Getting a nicely formatted summary of our model (like in Keras). Pytorch doesn't support it natively. So, we need to install the `torchsummary` library (discussed earlier)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:41.526182Z",
     "iopub.status.busy": "2020-12-15T06:54:41.525236Z",
     "iopub.status.idle": "2020-12-15T06:54:42.238107Z",
     "shell.execute_reply": "2020-12-15T06:54:42.237349Z"
    },
    "papermill": {
     "duration": 0.865999,
     "end_time": "2020-12-15T06:54:42.238301",
     "exception": false,
     "start_time": "2020-12-15T06:54:41.372302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# getting summary of the model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m INPUT_SHAPE \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(summary(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mcuda(), (INPUT_SHAPE)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# getting summary of the model\n",
    "INPUT_SHAPE = (3, 256, 256)\n",
    "print(summary(model.cuda(), (INPUT_SHAPE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.14664,
     "end_time": "2020-12-15T06:54:42.545891",
     "exception": false,
     "start_time": "2020-12-15T06:54:42.399251",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🏋️ Training the model 🏋️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.150108,
     "end_time": "2020-12-15T06:54:42.844760",
     "exception": false,
     "start_time": "2020-12-15T06:54:42.694652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Before we train the model, Let’s define a utility functionan `evaluate` function, which will perform the validation phase, and a `fit_one_cycle` function which will perform the entire training process. In `fit_one_cycle`, we have use some techniques:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.152611,
     "end_time": "2020-12-15T06:54:43.147315",
     "exception": false,
     "start_time": "2020-12-15T06:54:42.994704",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- **Learning Rate Scheduling**: Instead of using a fixed learning rate, we will use a learning rate scheduler, which will change the learning rate after every batch of training. There are many strategies for varying the learning rate during training, and the one we’ll use is called the *“One Cycle Learning Rate Policy”*, which involves starting with a low learning rate, gradually increasing it batch-by-batch to a high learning rate for about 30% of epochs, then gradually decreasing it to a very low value for the remaining epochs.\n",
    "\n",
    "- **Weight Decay**: We also use weight decay, which is a regularization technique which prevents the weights from becoming too large by adding an additional term to the loss function. \n",
    "\n",
    "- **Gradient Clipping**: Apart from the layer weights and outputs, it also helpful to limit the values of gradients to a small range to prevent undesirable changes in parameters due to large gradient values. This simple yet effective technique is called gradient clipping.\n",
    "\n",
    "We'll also record the learning rate used for each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:43.464522Z",
     "iopub.status.busy": "2020-12-15T06:54:43.463494Z",
     "iopub.status.idle": "2020-12-15T06:54:43.466732Z",
     "shell.execute_reply": "2020-12-15T06:54:43.466153Z"
    },
    "papermill": {
     "duration": 0.169191,
     "end_time": "2020-12-15T06:54:43.466833",
     "exception": false,
     "start_time": "2020-12-15T06:54:43.297642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for training\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "\n",
    "def fit_OneCycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0,\n",
    "                grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "    \n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "    # scheduler for one cycle learniing rate\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            # gradient clipping\n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "                \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # recording and updating learning rates\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            sched.step()\n",
    "            \n",
    "    \n",
    "        # validation\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "        \n",
    "    return history\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.148385,
     "end_time": "2020-12-15T06:54:43.768339",
     "exception": false,
     "start_time": "2020-12-15T06:54:43.619954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's check our validation loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:44.229384Z",
     "iopub.status.busy": "2020-12-15T06:54:44.228659Z",
     "iopub.status.idle": "2020-12-15T06:56:16.949501Z",
     "shell.execute_reply": "2020-12-15T06:56:16.948857Z"
    },
    "papermill": {
     "duration": 93.028639,
     "end_time": "2020-12-15T06:56:16.949629",
     "exception": false,
     "start_time": "2020-12-15T06:54:43.920990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = [evaluate(model, valid_dl)]\n",
    "history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.157995,
     "end_time": "2020-12-15T06:56:17.282823",
     "exception": false,
     "start_time": "2020-12-15T06:56:17.124828",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since there are randomly initialized weights, that is why accuracy come to near 0.019 (that is 1.9% chance of getting the right answer or you can say model randomly chooses a class).\n",
    "Now, declare some hyper parameters for the training of the model. We can change it if result is not satisfactory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:56:17.600661Z",
     "iopub.status.busy": "2020-12-15T06:56:17.598919Z",
     "iopub.status.idle": "2020-12-15T06:56:17.601325Z",
     "shell.execute_reply": "2020-12-15T06:56:17.601787Z"
    },
    "papermill": {
     "duration": 0.162208,
     "end_time": "2020-12-15T06:56:17.601908",
     "exception": false,
     "start_time": "2020-12-15T06:56:17.439700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "max_lr = 0.01\n",
    "grad_clip = 0.1\n",
    "weight_decay = 1e-4\n",
    "opt_func = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.157106,
     "end_time": "2020-12-15T06:56:17.913801",
     "exception": false,
     "start_time": "2020-12-15T06:56:17.756695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's start training our model ....\n",
    "\n",
    "Note: The following cell may take 15 mins to 45 mins to run depending on your GPU. In kaggle (P100 GPU) it took around 20 mins of Wall Time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:56:18.447829Z",
     "iopub.status.busy": "2020-12-15T06:56:18.446899Z",
     "iopub.status.idle": "2020-12-15T07:16:12.440007Z",
     "shell.execute_reply": "2020-12-15T07:16:12.440757Z"
    },
    "papermill": {
     "duration": 1194.323015,
     "end_time": "2020-12-15T07:16:12.440924",
     "exception": false,
     "start_time": "2020-12-15T06:56:18.117909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history += fit_OneCycle(epochs, max_lr, model, train_dl, valid_dl, \n",
    "                             grad_clip=grad_clip, \n",
    "                             weight_decay=1e-4, \n",
    "                             opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.163552,
     "end_time": "2020-12-15T07:16:12.768145",
     "exception": false,
     "start_time": "2020-12-15T07:16:12.604593",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### We got an accuracy of 99.2 % 🙌🙌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.169551,
     "end_time": "2020-12-15T07:16:13.107269",
     "exception": false,
     "start_time": "2020-12-15T07:16:12.937718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 📈 Plotting 📈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.164374,
     "end_time": "2020-12-15T07:16:13.436479",
     "exception": false,
     "start_time": "2020-12-15T07:16:13.272105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Helper functions for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T07:16:13.764368Z",
     "iopub.status.busy": "2020-12-15T07:16:13.763714Z",
     "iopub.status.idle": "2020-12-15T07:16:13.768095Z",
     "shell.execute_reply": "2020-12-15T07:16:13.767310Z"
    },
    "papermill": {
     "duration": 0.17176,
     "end_time": "2020-12-15T07:16:13.768238",
     "exception": false,
     "start_time": "2020-12-15T07:16:13.596478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_accuracies(history):\n",
    "    accuracies = [x['val_accuracy'] for x in history]\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs');\n",
    "\n",
    "def plot_losses(history):\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs');\n",
    "    \n",
    "def plot_lrs(history):\n",
    "    lrs = np.concatenate([x.get('lrs', []) for x in history])\n",
    "    plt.plot(lrs)\n",
    "    plt.xlabel('Batch no.')\n",
    "    plt.ylabel('Learning rate')\n",
    "    plt.title('Learning Rate vs. Batch no.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.156803,
     "end_time": "2020-12-15T07:16:14.082237",
     "exception": false,
     "start_time": "2020-12-15T07:16:13.925434",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T07:16:14.408742Z",
     "iopub.status.busy": "2020-12-15T07:16:14.407718Z",
     "iopub.status.idle": "2020-12-15T07:16:14.572814Z",
     "shell.execute_reply": "2020-12-15T07:16:14.573361Z"
    },
    "papermill": {
     "duration": 0.331211,
     "end_time": "2020-12-15T07:16:14.573505",
     "exception": false,
     "start_time": "2020-12-15T07:16:14.242294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_accuracies(\u001b[43mhistory\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_accuracies(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.163962,
     "end_time": "2020-12-15T07:16:14.905941",
     "exception": false,
     "start_time": "2020-12-15T07:16:14.741979",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T07:16:15.243562Z",
     "iopub.status.busy": "2020-12-15T07:16:15.242443Z",
     "iopub.status.idle": "2020-12-15T07:16:15.434328Z",
     "shell.execute_reply": "2020-12-15T07:16:15.433718Z"
    },
    "papermill": {
     "duration": 0.366892,
     "end_time": "2020-12-15T07:16:15.434461",
     "exception": false,
     "start_time": "2020-12-15T07:16:15.067569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_losses(\u001b[43mhistory\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.172962,
     "end_time": "2020-12-15T07:16:15.786238",
     "exception": false,
     "start_time": "2020-12-15T07:16:15.613276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Learning Rate overtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T07:16:16.154344Z",
     "iopub.status.busy": "2020-12-15T07:16:16.152541Z",
     "iopub.status.idle": "2020-12-15T07:16:16.294279Z",
     "shell.execute_reply": "2020-12-15T07:16:16.294829Z"
    },
    "papermill": {
     "duration": 0.33312,
     "end_time": "2020-12-15T07:16:16.294990",
     "exception": false,
     "start_time": "2020-12-15T07:16:15.961870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plot_lrs(\u001b[43mhistory\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plot_lrs(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.163691,
     "end_time": "2020-12-15T07:16:16.647423",
     "exception": false,
     "start_time": "2020-12-15T07:16:16.483732",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🧪 Testing model on test data 🧪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.160512,
     "end_time": "2020-12-15T07:16:16.972329",
     "exception": false,
     "start_time": "2020-12-15T07:16:16.811817",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**We only have 33 images in test data, so let's check the model on all images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T07:16:17.486559Z",
     "iopub.status.busy": "2020-12-15T07:16:17.485301Z",
     "iopub.status.idle": "2020-12-15T07:16:17.501849Z",
     "shell.execute_reply": "2020-12-15T07:16:17.503584Z"
    },
    "papermill": {
     "duration": 0.287752,
     "end_time": "2020-12-15T07:16:17.503784",
     "exception": false,
     "start_time": "2020-12-15T07:16:17.216032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../input/new-plant-diseases-dataset/test'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m test_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../input/new-plant-diseases-dataset/test\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mToTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py:309\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    303\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    307\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    308\u001b[0m ):\n\u001b[1;32m--> 309\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py:144\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    136\u001b[0m     root: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m     is_valid_file: Optional[Callable[[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mbool\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    142\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, transform\u001b[38;5;241m=\u001b[39mtransform, target_transform\u001b[38;5;241m=\u001b[39mtarget_transform)\n\u001b[1;32m--> 144\u001b[0m     classes, class_to_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m loader\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py:218\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m    192\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py:40\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_classes\u001b[39m(directory: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Finds the class folders in a dataset.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    See :class:`DatasetFolder` for details.\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(entry\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscandir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m entry\u001b[38;5;241m.\u001b[39mis_dir())\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../input/new-plant-diseases-dataset/test'"
     ]
    }
   ],
   "source": [
    "test_dir = \"../input/new-plant-diseases-dataset/test\"\n",
    "test = ImageFolder(test_dir, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T07:16:17.927154Z",
     "iopub.status.busy": "2020-12-15T07:16:17.925594Z",
     "iopub.status.idle": "2020-12-15T07:16:17.930241Z",
     "shell.execute_reply": "2020-12-15T07:16:17.930740Z"
    },
    "papermill": {
     "duration": 0.177962,
     "end_time": "2020-12-15T07:16:17.930865",
     "exception": false,
     "start_time": "2020-12-15T07:16:17.752903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '../input/new-plant-diseases-dataset/test/test'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/test\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m# since images in test folder are in alphabetical order\u001b[39;00m\n\u001b[0;32m      2\u001b[0m test_images\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../input/new-plant-diseases-dataset/test/test'"
     ]
    }
   ],
   "source": [
    "test_images = sorted(os.listdir(test_dir + '/test')) # since images in test folder are in alphabetical order\n",
    "test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T07:16:18.277682Z",
     "iopub.status.busy": "2020-12-15T07:16:18.275745Z",
     "iopub.status.idle": "2020-12-15T07:16:18.278376Z",
     "shell.execute_reply": "2020-12-15T07:16:18.278875Z"
    },
    "papermill": {
     "duration": 0.17446,
     "end_time": "2020-12-15T07:16:18.278995",
     "exception": false,
     "start_time": "2020-12-15T07:16:18.104535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    \"\"\"Converts image to array and return the predicted class\n",
    "        with highest probability\"\"\"\n",
    "    # Convert to a batch of 1\n",
    "    xb = to_device(img.unsqueeze(0), device)\n",
    "    # Get predictions from model\n",
    "    yb = model(xb)\n",
    "    # Pick index with highest probability\n",
    "    _, preds  = torch.max(yb, dim=1)\n",
    "    # Retrieve the class label\n",
    "\n",
    "    return train.classes[preds[0].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T07:16:18.601686Z",
     "iopub.status.busy": "2020-12-15T07:16:18.600998Z",
     "iopub.status.idle": "2020-12-15T07:16:18.784752Z",
     "shell.execute_reply": "2020-12-15T07:16:18.784113Z"
    },
    "papermill": {
     "duration": 0.348624,
     "end_time": "2020-12-15T07:16:18.784870",
     "exception": false,
     "start_time": "2020-12-15T07:16:18.436246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# predicting first image\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m img, label \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(img\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel:\u001b[39m\u001b[38;5;124m'\u001b[39m, test_images[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, Predicted:\u001b[39m\u001b[38;5;124m'\u001b[39m, predict_image(img, model))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "# predicting first image\n",
    "img, label = test[0]\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "print('Label:', test_images[0], ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T07:16:19.123586Z",
     "iopub.status.busy": "2020-12-15T07:16:19.122676Z",
     "iopub.status.idle": "2020-12-15T07:16:19.565853Z",
     "shell.execute_reply": "2020-12-15T07:16:19.566653Z"
    },
    "papermill": {
     "duration": 0.612956,
     "end_time": "2020-12-15T07:16:19.566789",
     "exception": false,
     "start_time": "2020-12-15T07:16:18.953833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# getting all predictions (actual label vs predicted)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (img, label) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtest\u001b[49m):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel:\u001b[39m\u001b[38;5;124m'\u001b[39m, test_images[i], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, Predicted:\u001b[39m\u001b[38;5;124m'\u001b[39m, predict_image(img, model))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "# getting all predictions (actual label vs predicted)\n",
    "for i, (img, label) in enumerate(test):\n",
    "    print('Label:', test_images[i], ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.164143,
     "end_time": "2020-12-15T07:16:19.895435",
     "exception": false,
     "start_time": "2020-12-15T07:16:19.731292",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**We can see that the model predicted all the test images perfectly!!!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.167812,
     "end_time": "2020-12-15T07:16:20.231512",
     "exception": false,
     "start_time": "2020-12-15T07:16:20.063700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.163261,
     "end_time": "2020-12-15T07:16:20.562790",
     "exception": false,
     "start_time": "2020-12-15T07:16:20.399529",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**There are several ways to save the model in Pytorch, following are the two most common ways**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.164625,
     "end_time": "2020-12-15T07:16:20.894579",
     "exception": false,
     "start_time": "2020-12-15T07:16:20.729954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. **Save/Load `state_dict` (Recommended)**\n",
    "\n",
    "When saving a model for inference, it is only necessary to save the trained model’s learned parameters. Saving the model’s `state_dict` with the `torch.save()` function will give you the most flexibility for restoring the model later, which is why it is the recommended method for saving models.\n",
    "\n",
    "A common PyTorch convention is to save models using either a `.pt` or `.pth` file extension.\n",
    "\n",
    "Remember that you must call `model.eval()` to set dropout and batch normalization layers to evaluation mode before running inference. Failing to do this will yield inconsistent inference results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T07:16:21.236912Z",
     "iopub.status.busy": "2020-12-15T07:16:21.236137Z",
     "iopub.status.idle": "2020-12-15T07:16:21.302803Z",
     "shell.execute_reply": "2020-12-15T07:16:21.302251Z"
    },
    "papermill": {
     "duration": 0.241697,
     "end_time": "2020-12-15T07:16:21.302920",
     "exception": false,
     "start_time": "2020-12-15T07:16:21.061223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# saving to the kaggle working directory\u001b[39;00m\n\u001b[0;32m      2\u001b[0m PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./plant-disease-model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m  \n\u001b[1;32m----> 3\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict(), PATH)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# saving to the kaggle working directory\n",
    "PATH = './plant-disease-model.pth'  \n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.163694,
     "end_time": "2020-12-15T07:16:21.634842",
     "exception": false,
     "start_time": "2020-12-15T07:16:21.471148",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "2. **Save/Load Entire Model**\n",
    "\n",
    "This save/load process uses the most intuitive syntax and involves the least amount of code. Saving a model in this way will save the entire module using Python’s [pickle](https://docs.python.org/3/library/pickle.html) module. The disadvantage of this approach is that the serialized data is bound to the specific classes and the exact directory structure used when the model is saved. The reason for this is because pickle does not save the model class itself. Rather, it saves a path to the file containing the class, which is used during load time. Because of this, your code can break in various ways when used in other projects or after refactors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T07:16:21.979277Z",
     "iopub.status.busy": "2020-12-15T07:16:21.973670Z",
     "iopub.status.idle": "2020-12-15T07:16:22.039546Z",
     "shell.execute_reply": "2020-12-15T07:16:22.038875Z"
    },
    "papermill": {
     "duration": 0.236439,
     "end_time": "2020-12-15T07:16:22.039674",
     "exception": false,
     "start_time": "2020-12-15T07:16:21.803235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# saving the entire model to working directory\u001b[39;00m\n\u001b[0;32m      2\u001b[0m PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./plant-disease-model-complete.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mmodel\u001b[49m, PATH)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# saving the entire model to working directory\n",
    "PATH = './plant-disease-model-complete.pth'\n",
    "torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.16871,
     "end_time": "2020-12-15T07:16:22.405604",
     "exception": false,
     "start_time": "2020-12-15T07:16:22.236894",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.176314,
     "end_time": "2020-12-15T07:16:22.749090",
     "exception": false,
     "start_time": "2020-12-15T07:16:22.572776",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "ResNets perform significantly well for image classification when some of the parameters are tweaked and techniques like scheduling learning rate, gradient clipping and weight decay are applied. The model is able to predict every image in test set perfectly without any errors !!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.165877,
     "end_time": "2020-12-15T07:16:23.081615",
     "exception": false,
     "start_time": "2020-12-15T07:16:22.915738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# References\n",
    "- [CIFAR10 ResNet Implementation](https://jovian.ai/aakashns/05b-cifar10-resnet)\n",
    "- [PyTorch docs](https://pytorch.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.163619,
     "end_time": "2020-12-15T07:16:23.414606",
     "exception": false,
     "start_time": "2020-12-15T07:16:23.250987",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "#### Hope you all learned something from this kernel. Do upvote if you find this useful.\n",
    "\n",
    "#### Happy Learning....\n",
    "\n",
    "#### Catch you guys on the next one\n",
    "\n",
    "#### Peace ✌️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "papermill": {
   "duration": 1424.697889,
   "end_time": "2020-12-15T07:16:24.493770",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-15T06:52:39.795881",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
